import streamlit as st
import time
import random
import os
from questions import QUESTIONS

# LLM ëª¨ë“ˆ ìž„í¬íŠ¸
try:
    # evaluate_interview ìž„í¬íŠ¸ ì¶”ê°€
    from llm_manager import generate_dynamic_question, get_ai_response, transcribe_audio, text_to_speech, evaluate_interview
    HAS_LLM = True
except ImportError as e:
    HAS_LLM = False
    st.error(f"LLM Module Import Error: {e}")

# ìŒì„± ë…¹ìŒê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from streamlit_mic_recorder import mic_recorder
    HAS_AUDIO = True
except ImportError:
    HAS_AUDIO = False

# íŽ˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì˜ëŒ€ ë©´ì ‘ ì—°ìŠµ ì±—ë´‡ (AI)",
    page_icon="ðŸ©º",
    layout="wide"
)

# --- ìƒíƒœ ì´ˆê¸°í™” (ì‚¬ì´ë“œë°” ë Œë”ë§ ì „) ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.evaluation = None
    st.session_state.current_question_index = 0
    
    # ì´ˆê¸°: ê¸°ì¶œ ë¬¸ì œ ì¤‘ ë¬´ìž‘ìœ„ ì„ íƒ
    random_key = random.choice(list(QUESTIONS.keys()))
    st.session_state.current_question = QUESTIONS[random_key]
    
    # ì„±ê²© ë¬´ìž‘ìœ„ ì„ íƒ (0, 1, 2 ì¤‘ í•˜ë‚˜)
    st.session_state.personality_index = random.randint(0, 2)

# ì•ˆì „ìž¥ì¹˜: ê¸°ì¡´ ì„¸ì…˜ì— personality_indexê°€ ì—†ì„ ê²½ìš° ì¶”ê°€
if "personality_index" not in st.session_state:
    st.session_state.personality_index = random.randint(0, 2)

q_data = st.session_state.current_question

# --- ì‚¬ì´ë“œë°”: ì„¤ì • ---
with st.sidebar:
    st.header("ðŸ¤– ë©´ì ‘ê´€ ì„¤ì •")
    
    # 0. API í‚¤ ì„¤ì •
    if "OPENAI_API_KEY" in st.secrets:
        os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
        api_key = st.secrets["OPENAI_API_KEY"]
        st.success("âœ… API Keyê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        api_key = st.text_input("OpenAI API Key:", type="password", placeholder="sk-...")
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key

    # 1. ì„±ê²© ì„ íƒ
    personality_map = {
        0: "ëƒ‰ì² í•˜ê³  ì••ë°•í•˜ëŠ” ìŠ¤íƒ€ì¼",
        1: "ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ìŠ¤íƒ€ì¼",
        2: "ë…¼ë¦¬ì ì´ê³  ì‚¬ì‹¤ ì¤‘ì‹¬ ìŠ¤íƒ€ì¼"
    }

    voice_map = {
        0: "onyx",
        1: "shimmer",
        2: "alloy"
    }
    
    selected_p_index = st.radio(
        "ë©´ì ‘ê´€ ì„±ê²©:",
        [0, 1, 2],
        format_func=lambda x: personality_map[x],
        index=st.session_state.personality_index
    )
    
    st.session_state.personality_index = selected_p_index
    personality = personality_map[selected_p_index]
    current_voice = voice_map[selected_p_index]
    
    st.markdown("---")
    
    # 2. ë¬¸ì œ ì„ íƒ
    st.header("ðŸ“š ê¸°ì¶œ ë¬¸ì œ / AI ìƒì„±")
    
    tab1, tab2 = st.tabs(["ê¸°ì¶œ ë¬¸ì œ", "AI ë¬¸ì œ ìƒì„±"])
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜
    def reset_session(new_question=None):
        st.session_state.messages = []
        st.session_state.evaluation = None # í‰ê°€ ê²°ê³¼ ì´ˆê¸°í™”
        st.session_state.current_question_index = 0
        
        # ì„±ê²©ë„ ë‹¤ì‹œ ëžœë¤ (ì›í•œë‹¤ë©´) - UXìƒ ë¦¬ì…‹ì‹œ ëª¨ë“ ê²Œ ë°”ë€ŒëŠ”ê²Œ ìžì—°ìŠ¤ëŸ¬ì›€
        st.session_state.personality_index = random.randint(0, 2)
        
        if new_question:
            st.session_state.current_question = new_question
        else:
             # ê¸°ì¶œ ë¬¸ì œ ì¤‘ ë¬´ìž‘ìœ„ ìž¬ì„ íƒ
            random_key = random.choice(list(QUESTIONS.keys()))
            st.session_state.current_question = QUESTIONS[random_key]
    
    with tab1:
        question_category = st.selectbox(
            "ê¸°ì¶œ ë¬¸ì œ ì£¼ì œ:",
            list(QUESTIONS.keys())
        )
        if st.button("ê¸°ì¶œ ë¬¸ì œë¡œ ì‹œìž‘"):
            reset_session(QUESTIONS[question_category])
            st.rerun()
            
    with tab2:
        new_topic = st.text_input("ìƒì„±í•  ë¬¸ì œ ì£¼ì œ:", placeholder="ì˜ˆ: ì˜ë£Œ ì¸ê³µì§€ëŠ¥, ì•ˆë½ì‚¬ ë“±")
        if st.button("ìƒˆë¡œìš´ ë¬¸ì œ ìƒì„± (AI)"):
            if not api_key:
                st.error("API Keyë¥¼ ë¨¼ì € ìž…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("AIê°€ ê¸°ì¶œ ë¬¸ì œë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ì¶œì œ ì¤‘ìž…ë‹ˆë‹¤..."):
                    generated_q = generate_dynamic_question(api_key, new_topic)
                    if "error" in generated_q:
                        st.error(f"ìƒì„± ì‹¤íŒ¨: {generated_q['error']}")
                    else:
                        reset_session(generated_q)
                        st.rerun()

    st.markdown("---")
    
    # 3. í‰ê°€ ë° ì´ˆê¸°í™”
    if st.button("ðŸ ë©´ì ‘ ì¢…ë£Œ ë° í‰ê°€ë°›ê¸°"):
        if not st.session_state.messages:
             st.warning("ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        elif not api_key:
             st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            with st.spinner("ë©´ì ‘ê´€ì´ í‰ê°€ì„œë¥¼ ìž‘ì„±í•˜ê³  ìžˆìŠµë‹ˆë‹¤... (ì•½ 10ì´ˆ ì†Œìš”)"):
                # í‰ê°€ ë¡œì§ ì‹¤í–‰
                eval_result = evaluate_interview(
                    api_key, 
                    st.session_state.messages, 
                    st.session_state.current_question
                )
                st.session_state.evaluation = eval_result
                st.rerun() # ë¦¬ëŸ°í•´ì„œ ë©”ì¸ í™”ë©´ì— ë¿Œë¦¼

    if st.button("ðŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        reset_session()
        st.rerun()

# --- ë©”ì¸ í™”ë©´ ---
st.title("ðŸ©º ì˜ëŒ€ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜")

# Evaluation used to be displayed here, now moved to bottom
st.markdown("---")

# [1] ì œì‹œë¬¸ ë° ë¬¸ì œ ì˜ì—­ (ìžê¸°ì†Œê°œ ì „ì—ëŠ” ìˆ¨ê¸¸ ìˆ˜ë„ ìžˆì§€ë§Œ, ë¯¸ë¦¬ ë³´ì—¬ì£¼ëŠ” ê²Œ ë‚˜ì„ ìˆ˜ ìžˆìŒ)
# ì¼ë‹¨ í•­ìƒ ë³´ì—¬ì¤Œ
with st.expander("ðŸ“„ ì œì‹œë¬¸ ë° ë¬¸ì œ ë³´ê¸°", expanded=True):
    st.subheader(q_data.get("title", "ì œëª© ì—†ìŒ"))
    st.markdown(q_data.get("context", ""))
    st.markdown("---")
    st.markdown("**ì§ˆë¬¸ ëª©ë¡**")
    questions = q_data.get("questions", [])
    if isinstance(questions, list):
        # í˜„ìž¬ ì§ˆë¬¸ í•˜ì´ë¼ì´íŠ¸
        current_idx = st.session_state.current_question_index
        for idx, q in enumerate(questions):
            if idx == current_idx:
                st.markdown(f"**ðŸ‘‰ {q}**")
            else:
                st.markdown(f"- {q}")
    else:
        st.write(questions)

# [2] ì²«ì¸ì‚¬ (ì²« ë²ˆì§¸ ì§ˆë¬¸ ì œì‹œ)
if not st.session_state.messages:
    first_q = q_data['questions'][0]
    welcome_msg = f"ë°˜ê°‘ìŠµë‹ˆë‹¤. ë©´ì ‘ì„ ì‹œìž‘í•˜ê² ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì§ˆë¬¸ìž…ë‹ˆë‹¤.\n\n{first_q}"
    msg_data = {"role": "assistant", "content": welcome_msg}
    
    # TTS ìƒì„± (ì²« ì¸ì‚¬ë„ ìŒì„±ìœ¼ë¡œ)
    if HAS_LLM and api_key:
        try:
            # ë§¤ë²ˆ ìƒì„±í•˜ë©´ ëŠë¦¬ê±°ë‚˜ ë¹„ìš©ì´ ë“œë‹ˆ ì„¸ì…˜ì— ìºì‹±í•˜ë©´ ì¢‹ìœ¼ë‚˜,
            # ì—¬ê¸°ì„  ê°„ë‹¨ížˆ í•­ìƒ ìƒì„± (ë˜ëŠ” ì´ë¯¸ ìƒì„±ëœ ê±¸ í™•ì¸ ê°€ëŠ¥í•˜ë©´ ì¢‹ìŒ)
            audio_bytes = text_to_speech(api_key, welcome_msg, voice=current_voice)
            msg_data["audio"] = audio_bytes
        except Exception:
            pass # API í‚¤ ì˜¤ë¥˜ ë“±ìœ¼ë¡œ ìƒì„± ëª»í•´ë„ í…ìŠ¤íŠ¸ëŠ” ë³´ì—¬ì¤Œ
            
    st.session_state.messages.append(msg_data)

# Sidebar nav removed

# [3] ëŒ€í™” í‘œì‹œ
# [3] ëŒ€í™” í‘œì‹œ
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.write(message["content"])
        if "audio" in message:
            # ê°€ìž¥ ìµœê·¼ ë©”ì‹œì§€ë§Œ ìžë™ ìž¬ìƒ (autoplay=True)
            is_last = (idx == len(st.session_state.messages) - 1)
            st.audio(message["audio"], format="audio/mp3", autoplay=is_last)

# --- ìž…ë ¥ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ OR ì˜¤ë””ì˜¤) ---
# í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ìž…ë ¥ì°½ì„ ìˆ¨ê¹€ (ë©´ì ‘ ì¢…ë£Œ)
# í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ìž…ë ¥ì°½ì„ ìˆ¨ê¹€ (ë©´ì ‘ ì¢…ë£Œ)
# Dynamic Container for Input Area

# Dynamic Container for Input Area or Next Button
input_container = st.empty()

if not st.session_state.get("evaluation"):
    # Determine state: Can we move to next question?
    # Logic: If last message is assistant (ack) and we are not at end, show Next Button.
    # Otherwise, show Input.
    
    current_idx = st.session_state.current_question_index
    total_q = len(q_data['questions'])
    
    show_next_button = False
    
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
         # Only show if the PREVIOUS message was from user (meaning this assistant message is a response/ack)
         # Start of interview: [Assistant(Welcome)] -> Len 1. [-2] Index Error.
         if len(st.session_state.messages) > 1 and st.session_state.messages[-2]["role"] == "user":
             if current_idx < total_q - 1:
                 show_next_button = True
    
    with input_container.container():
        # Initialize variables to avoid NameError
        audio_bytes = None
        user_input_content = None

        if show_next_button:
            # [CASE 1] Auto-Advance to Next Question (No Button)
            st.info("â³ ë‹µë³€ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤...")
            
            # Give user time to read/hear the acknowledgement
            time.sleep(3)
            
            st.session_state.current_question_index += 1
            next_q = q_data['questions'][st.session_state.current_question_index]
            
            # ë‹¤ìŒ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„±
            next_msg_text = f"ë‹¤ìŒ ì§ˆë¬¸ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n{next_q}"
            msg_data = {"role": "assistant", "content": next_msg_text}
            
            if HAS_LLM and api_key:
                try:
                    audio_bytes = text_to_speech(api_key, next_msg_text, voice=current_voice)
                    msg_data["audio"] = audio_bytes
                except Exception:
                    pass
            
            st.session_state.messages.append(msg_data)
            st.rerun()
        
        else:
            # [CASE 2] Show Input Controls (Audio/Text)
            # ì±„íŒ… ìž…ë ¥ì°½ ë°”ë¡œ ìœ„ì— ì˜¤ë””ì˜¤ ë²„íŠ¼ ë°°ì¹˜
            st.markdown("### ðŸ’¬ ë‹µë³€í•˜ê¸°")
            
            # audio_bytes = None # Removed redundancy
            # user_input_content = None # Removed redundancy

            if HAS_AUDIO:
                # mic_recorderëŠ” ë²„íŠ¼ í˜•íƒœë¡œ ë Œë”ë§ë¨
                c1, c2 = st.columns([2, 8])
                with c1:
                    st.write("ë§ˆì´í¬ë¥¼ ì¼œê³  ë§ì”€í•˜ì„¸ìš”:")
                with c2:
                    # ë…¹ìŒ ë²„íŠ¼
                    audio_data = mic_recorder(
                        start_prompt="ðŸŽ¤ ë…¹ìŒ ì‹œìž‘",
                        stop_prompt="â¹ï¸ ë§í•˜ê¸° ì™„ë£Œ (í´ë¦­ ì‹œ ì „ì†¡)",
                        key='recorder',
                        format="wav",
                        use_container_width=False
                    )
                    if audio_data:
                        audio_bytes = audio_data['bytes']

            # í…ìŠ¤íŠ¸ ìž…ë ¥ (í™”ë©´ í•˜ë‹¨ ê³ ì •)
        prompt = st.chat_input("í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ì„ ìž…ë ¥í•˜ì„¸ìš”...")
else:
    # ë©´ì ‘ ì¢…ë£Œ ì‹œ ì•ˆë‚´ (Evaluation block will show result below)
    # Clear the input container just in case
    input_container.empty()
    st.info("âœ… ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ëž˜ í‰ê°€ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    audio_bytes = None
    prompt = None
    user_input_content = None

# ë¡œì§: ì˜¤ë””ì˜¤ê°€ ë“¤ì–´ì˜¤ë©´ STT -> user_input_contentì— í• ë‹¹
if HAS_AUDIO and audio_bytes:
    with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ìž…ë‹ˆë‹¤..."):
        if api_key:
            try:
                user_input_content = transcribe_audio(api_key, audio_bytes)
            except Exception as e:
                st.error(f"STT Error: {e}")
        else:
             user_input_content = "[Mock] API Keyê°€ ì—†ì–´ì„œ ìŒì„± ì¸ì‹ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."

if prompt:
    user_input_content = prompt

# --- ë´‡ ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬ ---
# user_input_contentê°€ ìžˆì„ ë•Œë§Œ ì‹¤í–‰ (í‰ê°€ ì™„ë£Œ ì‹œì—ëŠ” prompt/audioê°€ Noneì´ë¯€ë¡œ ì‹¤í–‰ ì•ˆ ë¨)
if user_input_content:
    # 1. ì‚¬ìš©ìž ë©”ì‹œì§€ ì €ìž¥
    st.session_state.messages.append({"role": "user", "content": user_input_content})
    st.chat_message("user").write(user_input_content)
    
    # 2. ë´‡ ì‘ë‹µ ë¡œì§ ê²°ì •
    response_content = ""
    response_audio = None
    
    with st.chat_message("assistant"):
        with st.spinner("ë©´ì ‘ê´€ì´ ìƒê° ì¤‘ìž…ë‹ˆë‹¤..."):
            if HAS_LLM and api_key:
                # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì—¬ë¶€ í™•ì¸
                is_last = (st.session_state.current_question_index == len(q_data.get('questions', [])) - 1)
                
                # ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸°
                response_content = get_ai_response(
                    api_key, 
                    st.session_state.messages, 
                    personality, 
                    q_data,
                    is_last_question=is_last
                )
                
                # 2-2. TTS
                try:
                    with st.spinner("ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ë§í•˜ëŠ” ì¤‘ìž…ë‹ˆë‹¤..."):
                        response_audio = text_to_speech(api_key, response_content, voice=current_voice)
                except Exception as e:
                    st.error(f"TTS Error: {e}")
            else:
                time.sleep(1)
                response_content = f"[Mock] API Keyê°€ ì—†ìŠµë‹ˆë‹¤. ('{user_input_content}' ìˆ˜ì‹ )"
            
            # í…ìŠ¤íŠ¸ í‘œì‹œ
            st.write(response_content)
            # ì˜¤ë””ì˜¤ í”Œë ˆì´
            if response_audio:
                st.audio(response_audio, format="audio/mp3", autoplay=True)
    
    # ë©”ì‹œì§€ ì €ìž¥ (ì˜¤ë””ì˜¤ í¬í•¨)
    msg_data = {"role": "assistant", "content": response_content}
    if response_audio:
        msg_data["audio"] = response_audio
    st.session_state.messages.append(msg_data)
    
    # Force UI update to show "Next Question" button if applicable
    # If not the last question, rerun to update the input container state (Input -> Next Button)
    if current_idx < len(q_data.get('questions', [])) - 1:
         st.rerun()

    # [Auto-Evaluation] ë§ˆì§€ë§‰ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ê¹Œì§€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
    total_q = len(q_data.get('questions', []))
    current_idx = st.session_state.current_question_index
    
    # ì§€ê¸ˆ Indexê°€ ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ê³ , ë°©ê¸ˆ ë´‡ì´ ë‹¤ì†Œê³³ì´(ack) ëŒ€ë‹µí–ˆìœ¼ë¯€ë¡œ ì¸í„°ë·° ì¢…ë£Œë¡œ ê°„ì£¼
    if current_idx == total_q - 1:
        # ìžë™ í‰ê°€ ì‹¤í–‰
        if HAS_LLM and api_key:
            with st.spinner("ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë©´ì ‘ê´€ì´ í‰ê°€ì„œë¥¼ ìž‘ì„± ì¤‘ìž…ë‹ˆë‹¤... (ì•½ 10ì´ˆ ì†Œìš”)"):
                try:
                    eval_result = evaluate_interview(
                        api_key, 
                        st.session_state.messages, 
                        st.session_state.current_question
                    )
                    st.session_state.evaluation = eval_result
                    
                    # Force clear the input area immediately so user can't input more
                    input_container.empty() 
                    
                    # DO NOT rerun here to allow audio to finish playing
                    # st.rerun()
                except Exception as e:
                    st.error(f"Evaluation Error: {e}")

# --- í‰ê°€ ê²°ê³¼ í‘œì‹œ (ëŒ€í™” ì•„ëž˜ë¡œ ì´ë™) ---
if st.session_state.get("evaluation"):
    st.markdown("---")
    st.info("ðŸ“Š ë©´ì ‘ í‰ê°€ ê²°ê³¼ê°€ ë„ì°©í–ˆìŠµë‹ˆë‹¤!")
    with st.container(border=True):
        st.markdown(st.session_state.evaluation)
    # ë‹«ê¸° ë²„íŠ¼ì€ êµ³ì´ í•„ìš” ì—†ì„ ìˆ˜ë„ ìžˆì§€ë§Œ, ìž¬ì‹œí—˜ ë“±ì„ ìœ„í•´ ë‚¨ê²¨ë‘˜ ìˆ˜ ìžˆìŒ.
    # í•˜ì§€ë§Œ ì•„ëž˜ì— ë°°ì¹˜ë˜ë¯€ë¡œ 'ë‹«ê¸°'ë³´ë‹¤ëŠ” ê·¸ëƒ¥ ë³´ì—¬ì£¼ëŠ” ê²Œ ë‚˜ìŒ.
